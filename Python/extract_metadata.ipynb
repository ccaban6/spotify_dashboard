{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4d6b947",
   "metadata": {},
   "source": [
    "## Scraping Functions\n",
    "\n",
    "Below are some of the functions that I used for scraping. I don't remember having issues with it, but feel free to either scrap or modify it as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17038a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from typing import List, Dict, Any\n",
    "from datetime import datetime\n",
    "\n",
    "# Rate limiting constants\n",
    "MAX_REQUESTS_PER_MINUTE = 30  # Spotify's standard rate limit\n",
    "REQUEST_INTERVAL = 60 / MAX_REQUESTS_PER_MINUTE  # Seconds between requests\n",
    "last_request_time = 0\n",
    "\n",
    "def rate_limited_request():\n",
    "    \"\"\"Enforce rate limiting between API calls\"\"\"\n",
    "    global last_request_time\n",
    "    \n",
    "    current_time = time.time()\n",
    "    elapsed = current_time - last_request_time\n",
    "    wait_time = max(0, REQUEST_INTERVAL - elapsed)\n",
    "    \n",
    "    if wait_time > 0:\n",
    "        print(f\"Rate limiting: Waiting {wait_time:.2f} seconds\")\n",
    "        time.sleep(wait_time)\n",
    "    \n",
    "    last_request_time = time.time()\n",
    "\n",
    "def get_spotify_data(track_ids: List[str]) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Get comprehensive Spotify data for tracks including:\n",
    "    - Track info (popularity, duration_ms)\n",
    "    - Artist info (genres, popularity)\n",
    "    \"\"\"\n",
    "    # Process tracks in batches\n",
    "    track_data = process_in_batches(\n",
    "        items=track_ids,\n",
    "        batch_size=50,\n",
    "        process_function=get_track_batch_data\n",
    "    )\n",
    "\n",
    "    artist_ids = list(set(\n",
    "        artist['id']\n",
    "        for track in track_data\n",
    "        for artist in track['artists']  \n",
    "    ))\n",
    "    \n",
    "    # Verify we found all artists\n",
    "    print(f\"Found {len(artist_ids)} unique artist IDs to lookup\")\n",
    "    \n",
    "    # Process artists in batches\n",
    "    artist_data = process_in_batches(\n",
    "        items=artist_ids,\n",
    "        batch_size=50,\n",
    "        process_function=get_artist_batch_data\n",
    "    )\n",
    "    \n",
    "    # Create lookup with verification\n",
    "    artist_lookup = {artist['id']: artist for artist in artist_data}\n",
    "    \n",
    "    # Verify no missing artists\n",
    "    missing_artists = [\n",
    "        artist['id']\n",
    "        for track in track_data\n",
    "        for artist in track['artists']\n",
    "        if artist['id'] not in artist_lookup\n",
    "    ]\n",
    "    \n",
    "    if missing_artists:\n",
    "        print(f\"Warning: {len(missing_artists)} artist IDs not found in lookup\")\n",
    "        print(\"Sample missing IDs:\", missing_artists[:5])\n",
    "    \n",
    "    # Combine data\n",
    "    combined_data = []\n",
    "    for track in track_data:\n",
    "        for artist in track['artists']:  # Handle all artists per track\n",
    "            if artist['id'] in artist_lookup:\n",
    "                combined_data.append({\n",
    "                    'track_id': track['id'],\n",
    "                    'track_name': track['name'],\n",
    "                    'track_popularity': track['popularity'],\n",
    "                    'duration_ms': track['duration_ms'],\n",
    "                    'artist_id': artist['id'],\n",
    "                    'artist_name': artist['name'],\n",
    "                    'artist_popularity': artist_lookup[artist['id']]['popularity'],\n",
    "                    'genres': artist_lookup[artist['id']]['genres']\n",
    "                })\n",
    "            else:\n",
    "                print(f\"Artist {artist['id']} ({artist.get('name', 'unknown')}) not found in lookup for track {track['id']}\")\n",
    "    \n",
    "    return combined_data\n",
    "\n",
    "def get_track_batch_data(track_ids: List[str]) -> List[Dict[str, Any]]:\n",
    "    \"\"\"Get track data for a batch of track IDs with rate limiting\"\"\"\n",
    "    rate_limited_request()\n",
    "    try:\n",
    "        return sp.tracks(track_ids)['tracks']\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching tracks: {e}\")\n",
    "        return []\n",
    "\n",
    "def get_artist_batch_data(artist_ids: List[str]) -> List[Dict[str, Any]]:\n",
    "    \"\"\"Get artist data for a batch of artist IDs with rate limiting\"\"\"\n",
    "    rate_limited_request()\n",
    "    try:\n",
    "        return sp.artists(artist_ids)['artists']\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching artists: {e}\")\n",
    "        return []\n",
    "\n",
    "def process_in_batches(items: List[Any], batch_size: int, process_function: callable) -> List[Any]:\n",
    "    \"\"\"\n",
    "    Generic batch processing function with enhanced error handling\n",
    "    \n",
    "    Args:\n",
    "        items: List of items to process\n",
    "        batch_size: Number of items per batch\n",
    "        process_function: Function to process each batch\n",
    "        \n",
    "    Returns:\n",
    "        Combined results from all batches\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    total_items = len(items)\n",
    "    \n",
    "    for i in range(0, total_items, batch_size):\n",
    "        batch = items[i:i + batch_size]\n",
    "        print(f\"Processing batch {i//batch_size + 1}/{(total_items-1)//batch_size + 1} ({len(batch)} items) at {datetime.now().strftime('%H:%M:%S')}\")\n",
    "        \n",
    "        # Process the current batch with retry logic\n",
    "        max_retries = 3\n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                batch_result = process_function(batch)\n",
    "                if batch_result:  # Only extend if we got results\n",
    "                    results.extend(batch_result)\n",
    "                break\n",
    "            except Exception as e:\n",
    "                if attempt == max_retries - 1:\n",
    "                    print(f\"Failed to process batch after {max_retries} attempts: {e}\")\n",
    "                else:\n",
    "                    wait_time = (attempt + 1) * 5  # Exponential backoff\n",
    "                    print(f\"Attempt {attempt + 1} failed. Waiting {wait_time} seconds before retry...\")\n",
    "                    time.sleep(wait_time)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d246bc",
   "metadata": {},
   "source": [
    "## Loading Listening History Data\n",
    "\n",
    "You should have a joined file containing the data for all of the years and a Spotify Developer account to make API calls. You need the `client_id` and `secret_id` that they provide to authenticate your session and make API calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2971a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# load listening history\n",
    "df = pd.read_csv('listening_history.csv')\n",
    "\n",
    "# Load API keys\n",
    "with open('.keys.json', 'r') as f:\n",
    "    credentials = json.load(f)\n",
    "\n",
    "sp = spotipy.Spotify(auth_manager=SpotifyClientCredentials(client_id=credentials[\"Client ID\"],\n",
    "                                                           client_secret=credentials[\"Client Secret\"]))\n",
    "\n",
    "df.loc[:, 'Spotify Track Uri Clean'] = df['Spotify Track Uri'].str.replace('spotify:track:', '')\n",
    "\n",
    "spotify_data = get_spotify_data(df['Spotify Track Uri Clean'].unique().tolist()[:])\n",
    "\n",
    "spotify_metadata = pd.DataFrame(spotify_data)\n",
    "\n",
    "track_additional_features = spotify_metadata.copy()[['track_id', 'track_name', 'track_popularity', 'duration_ms']]\n",
    "track_additional_features['track_uri'] = \"spotify:track:\" + track_additional_features['track_id']\n",
    "track_additional_features = track_additional_features.drop_duplicates()\n",
    "track_additional_features.reset_index(drop=True, inplace=True)\n",
    "\n",
    "artist_additional_features = spotify_metadata.copy()[['artist_id', 'artist_name', 'artist_popularity', 'genres']]\n",
    "artist_additional_features = artist_additional_features.drop_duplicates(subset=['artist_id', 'artist_name', 'artist_popularity'])\n",
    "artist_additional_features.reset_index(drop=True, inplace=True)\n",
    "\n",
    "track_additional_features.to_excel('additional_track_features.xlsx', index=False, engine='openpyxl')\n",
    "artist_additional_features.to_excel('additional_artist_features.xlsx', index=False, engine='openpyxl')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
